{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Información del curso:\n",
    "- **Nombre del curso**: Introducción al aprendizaje automático\n",
    "- **Profesor**: Dr. Jesús Emmanuel Solís Pérez\n",
    "- **Email**: jsolisp@unam.mx\n",
    "- **Semestre**: 2025-1\n",
    "- **Fecha**: Diciembre 09, 2024\n",
    "- **Enlace del curso**: [https://jesolisp.github.io/Curso-Introduccion-Aprendizaje-Automatico](https://jesolisp.github.io/Curso-Introduccion-Aprendizaje-Automatico/docs/home.html)\n",
    "\n",
    "---\n",
    "\n",
    "### Información del Notebook:\n",
    "- **Título del Notebook**: Modelos de clasificación\n",
    "- **Versión**: 1.0\n",
    "- **Última modificación**: November 17, 2024\n",
    "- **Descripción**: Este cuaderno tiene como finalidad dar a conocer las aplicaciones y tipos de aprendizaje automático.\n",
    "\n",
    "---\n",
    "\n",
    "### Instrucciones:\n",
    "1. **Orden de ejecución de celdas**: Ejecute las celdas en el orden presentado para garantizar que las dependencias se manejen adecuadamente.\n",
    "2. **Envío**: Guarde y envíe este cuaderno como un archivo `.ipynb` antes de la fecha de vencimiento.\n",
    "3. **Comentarios y documentación**: asegúrese de agregar comentarios y documentación adecuados a su código.\n",
    "\n",
    "---\n",
    "\n",
    "### Licencia:\n",
    "- Este cuaderno se proporciona únicamente con fines educativos. Todos los derechos reservados © 2024 ENES Juriquilla.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación de modelos de clasificación\n",
    "\n",
    "En un clasificador binario sólo se evalúan dos clases: clase $0$ y clase $1$. Por ejemplo, para una base de datos de cáncer tenemos:\n",
    "\n",
    "* _Casos negativos_: Clase $1$ (masas malignas)\n",
    "* _Casos positivos_: Clase $0$ (masas benignas)\n",
    "\n",
    "De lo anterior, tenemos 4 tipos de observaciones:\n",
    "\n",
    "* **True Positives (TP)**. Masas malignas que se clasifican como malignas.\n",
    "* **False Positives (FP)**. Masas benignas que se clasifican como malignas.\n",
    "* **True Negatives (TN)**. Masas malignas que se clasifican como malignas.\n",
    "* **False Negatives (FN)**. Masas malignas que se clasifican como benignas.\n",
    "\n",
    "```{figure} images/TP-FP-FN-TN.png\n",
    " ---\n",
    " width: 340px\n",
    " height: 180px\n",
    " name: fig:TP-FP-FN-TN.png\n",
    " ---\n",
    " Imagen recuperada de {cite:t}`olson2015best`.\n",
    "```\n",
    "\n",
    "### Ratios de clasificación\n",
    "\n",
    "Para poder utilizar los siguientes ratios, es necesaria la siguiente instrucción: `from sklearn import metrics`\n",
    "\n",
    "* Accuracy (Exactitud)\n",
    "\n",
    "Mide la cantidad de casos que se han clasificado correctamente a partir de la siguiente ecuación\n",
    "\n",
    "$$\n",
    " ACC = \\frac{TP + TN}{TP + TN + FP + FN} = \\frac{\\text{Número de observaciones correctamente clasificadas}}{\\text{Número de observaciones totales}}.\n",
    "$$\n",
    "\n",
    "`metrics.accuracy_score(real_classes, predictions)`\n",
    "\n",
    "* Precission (Precisión)\n",
    "\n",
    "Mide la habilidad del modelo para clasificar los casos positivos como positivos\n",
    "\n",
    "$$\n",
    " PRE = \\frac{TP}{TP + FP} = \\frac{\\text{Número de observaciones positivas correctamente clasificadas}}{\\text{Número de observaciones clasificadas como positivas}}.\n",
    "$$\n",
    "\n",
    "`metrics.average_precision_score(real_classes, predictions)`\n",
    "\n",
    "* Sensitivity (Sensibilidad)\n",
    "\n",
    "Mide la habilidad del modelo para encontrar todos los casos positivos\n",
    "\n",
    "$$\n",
    " SEN = \\frac{TP}{TP + FN} = \\frac{\\text{Número de observaciones positivas clasificadas como positivas}}{\\text{Número de observaciones positivas totales}}\n",
    "$$\n",
    "\n",
    "`metrics.recall_score(real_classes, predictions)`\n",
    "\n",
    "* Matriz de confusión\n",
    "\n",
    "Una alternativa y sencilla de comparar cómo el modelo ha clasificado cada observación\n",
    "\n",
    "`from sklearn.metrics import confusion_matrix`\n",
    "\n",
    "`confusion_matrix(real_classes, predictions)`\n",
    "\n",
    "* F1 score\n",
    "\n",
    "Es una medida ponderada entre SEN y ACC:\n",
    "\n",
    "$$\n",
    " F_{1} = 2\\cdot \\frac{1}{\\frac{1}{ACC} + \\frac{1}{SEN}} = 2\\cdot \\frac{ACC\\cdot SEN}{ACC + SEN}.\n",
    "$$\n",
    "\n",
    "`metrics.f1_score(real_classes, predictions)`\n",
    "\n",
    "* False Positive Ratio\n",
    "\n",
    "Es una medida de las probabilidades del modelo para asignar una clase positiva a un caso negativo:\n",
    "\n",
    "$$\n",
    " FPR = \\frac{FP}{FP + TN} = \\frac{\\text{Número de observaciones negativas clasificadas como positivas}}{\\text{Número de observaciones negativas}}.\n",
    "$$\n",
    "\n",
    "`fpr(real_classes, predictions)`\n",
    "\n",
    "* Area Under the Curve (ROC-AUC)\n",
    "\n",
    "Permite encontrar un modelo que optimice la compensación entre FP y TP. El área debajo de la curva nos permite hacer la elección del modelo. Por ejemplo, si el área se encuentra al 100% entonces el modelo es capaz de distinguir entre resultados negativos y positivos la mayor parte del tiempo. Cuanto menor sea el área, peor será la clasificación.\n",
    "\n",
    "```{figure} images/ROC.png\n",
    " ---\n",
    " width: 340px\n",
    " height: 180px\n",
    " name: fig:ROC.png\n",
    " ---\n",
    "```\n",
    "\n",
    "`metrics.roc_auc_score(real_classes, predictions)`\n",
    "\n",
    "## Regresión logística\n",
    "\n",
    "Los modelos lineales suelen utilizarse para la clasificación. Para ello, consideramos una clasificación binaria utilizando la siguiente ecuación\n",
    "\n",
    "$$\n",
    " \\hat{y} = \\beta_{0}\\cdot x_{1} + \\beta_{1}\\cdot x_{2} + \\cdots + \\beta_{p}\\cdot x_{p} + b > 0.\n",
    "$$\n",
    "\n",
    "Como podemos observar, se parece mucho a la ecuación de un OLS con la diferencia de que establecemos el umbral del valor predicho en cero. Si la ecuación anterior es menor que cero, predecimos la clase $-1$; si es mayor que cero entonces la clase $+1$.\n",
    "\n",
    "| Modelo              | Variable objetivo  | Rango variable       |\n",
    "|:-------------------:|:------------------:|:--------------------:|\n",
    "| Regresión lineal    | Variable numérica  | (-$\\infty$,$\\infty$) |\n",
    "| Regresión logística | Probabilidad clase | $[0,1]$              |\n",
    "\n",
    "Un clasificador binario separa dos clases utilizando una línea, un plano o un hiperplano. Los dos algoritmos de clasificación lineal más utilizados son: **regresión logística** `linear_model.LogisticRegression` y **máquinas de soporte vectorial lineal** `svm.LinearSVC`.\n",
    "\n",
    "Al generar una línea, se puede caer en el error de obtener valores distintos de $0$ y $1$. Esto conlleva a que no se estaría cumpliendo la condición de la probabilidad debe estar en el intervalo $[0,1]$.\n",
    "\n",
    "Para evitar este problema, la regresión logística (Cox, 1958) transforma el valor obtenido por OLS con una función cuyo rango $\\in(0,1)$. En la literatura podemos encontrar diversas funciones que cumplen con lo anterior. La más utilizada es la **función logística** o **sigmoide**:\n",
    "\n",
    "$$\n",
    " \\varphi(\\eta) = \\frac{1}{1 + \\exp(-\\eta)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(-3,3,100)\n",
    "\n",
    "logsig = lambda n: 1/(1 + np.exp(-n)) # <--\n",
    "\n",
    "#def logsig(n):\n",
    "#    return 1/(1 + np.exp(-n))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x,logsig(x))\n",
    "plt.grid('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sustituyendo la ecuación del modelo lineal en la ecuación anterior para obtener:\n",
    "\n",
    "$$\n",
    " P(y=1|X = x) = \\frac{\\beta_{0}\\cdot x_{0} + \\beta_{1}\\cdot x_{1} + \\cdots + \\beta_{p}\\cdot x_{p} + b}{1 + \\exp\\left( \\beta_{0}\\cdot x_{0} + \\beta_{1}\\cdot x_{1} + \\cdots + \\beta_{p}\\cdot x_{p} + b \\right)},\n",
    "$$\n",
    "\n",
    "donde $P(y=1|X = x)$ se interpreta como la probabilidad de que $y$ adquiera el valor de $1$, dados los predictores $x_{0},x_{1},\\dots,x_{p}$.\n",
    "\n",
    "Ahora bien, `sklearn` permite trabajar con un modelo de regresión logística con un parámetro de compensación que rige la fuerza de la regularización llamado **C**. Aquí: \n",
    "\n",
    "* Si $C\\gg$, entonces el modelo intenta ajustarse al conjunto de entrenamiento lo mejor posible.\n",
    "* Si $C\\ll$, entonces el modelo intenta encontrar un vector de coeficientes $\\beta$ cercano a cero.\n",
    "\n",
    "Además, el parámetro C influye de la siguiente manera:\n",
    "\n",
    "* Si $C<$, entonces los algoritmos intenten ajustarse a la mayor cantidad de datos.\n",
    "* Si $C>$, entonces los algoritmos tratan de que se clasifiquen correctamente.\n",
    "\n",
    "```{note}\n",
    " Entiendase que $<$ denota un valor 'bajo' (pequeño) y $>$ denota un valor 'alto' (grande).\n",
    "```\n",
    "\n",
    "El valor por default en `linear_model.LogisticRegression` es $C = 1$ que proporciona un rendimiento bastante aceptable, con una precisión del 95% tanto en el conjunto de entrenamiento como en el de prueba.\n",
    "\n",
    "---\n",
    "### Ejemplo 1\n",
    "Para trabajar el modelo de regresión logística, vamos a utilizar la base de datos Cáncer de mama Wisconsin (diagnóstico) {cite}`BreastCancerWisconsin`\n",
    "\n",
    "En esta base de datos, las características se calculan a partir de una imagen digitalizada de una masa mamaria. \n",
    "\n",
    "**Información de los atributos**\n",
    "1. Número de identificación\n",
    "2. Diagnóstico (M = maligno, B = benigno)\n",
    "3-32)\n",
    "\n",
    "Se calculan diez características de valor real para cada núcleo celular:\n",
    "\n",
    "* radio (media de las distancias desde el centro hasta los puntos del perímetro)\n",
    "* textura (desviación estándar de los valores de la escala de grises)\n",
    "* perímetro\n",
    "* área\n",
    "* suavidad (variación local en longitudes de radio)\n",
    "* compacidad (perímetro ^ 2 / área - 1.0)\n",
    "* concavidad (severidad de las porciones cóncavas del contorno)\n",
    "* puntos cóncavos (número de porciones cóncavas del contorno)\n",
    "* simetría\n",
    "* dimensión fractal (\"aproximación de la línea costera\" - 1)\n",
    "\n",
    "La media, el error estándar y \"peor\" o mayor (media de los tres valores más grandes) de estas características se calcularon para cada imagen, resultando en 30 funciones. Por ejemplo, el campo 3 es Radio medio, campo 13 es Radio SE, el campo 23 es Peor radio (Dua y Graff, 2019).\n",
    "\n",
    "Todos los valores de las funciones se recodifican con cuatro dígitos significativos.\n",
    "\n",
    "Faltan valores de atributo: ninguno\n",
    "\n",
    "Distribución de clases: 357 benignas, 212 malignas\n",
    "\n",
    "Una de las imágenes digitalizadas que conforman la base de datos es la siguiente:\n",
    "\n",
    "<img src=\"pictures/dataset-card.jpg\" width=340 height=180 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _K_ vecinos más cercanos.\n",
    "## Árboles de decisión.\n",
    "## Máquinas de soporte vectorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
